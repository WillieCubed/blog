---
title: Lab Log - June 8, 2022
date: 2022-06-08
tags: [lab-log]
canonical_url: false
public: true
description: >
  Today, I downloaded some datasets.
---

# TL;DR

I learned that PyTorch was easier to use than I thought.

# Today's Research Goals

- Start reading about Meta's MDETR model
- Learn how to use PyTorch

# Completed Tasks

- I installed Nvidia's CUDA toolkit. Whew.
- Followed a PyTorch [guide](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
  and made a [script](https://gist.github.com/WillieCubed/15ab429db080abfa535ac2454b3423ee)
  that trains an image classification model
- Learned how to [load data in PyTorch](https://pytorch.org/tutorials/recipes/recipes/loading_data_recipe.html)
- Learn how autograd [works in PyTorch](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html)

Look at the thingies!

![A dog, a truck, a plane, and a dog]("../../static/assets/Dog Truck Plane Dog.png")

# Unresolved Things

- Still need to actually read the whole MDETR paper and successfully train the
  model.
- I have forgotten how to graph an image directly from a tensor using matplotlib.

I am pretty sure this is not an image:

![A dog, a truck, a plane, and a dog]("../../static/assets/Image Graph.png")

# Questions From Today

- (Completely off-topic, but) How can one do neurosymbolic learning with
  PyTorch?
- Is PyTorch Lightning any good?

# Other Notes

I feel like a dunce trying to do basic image classification with CIFAR in
PyTorch because I feel like I should be past this. However, I suppose it's
better to

I used to find autograd completely unapproachable, but the PyTorch docs were
relatively approachable.

I also see why researchers have gravitated to PyTorch instead of TensorFlow.
